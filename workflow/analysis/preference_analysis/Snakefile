# Snakemake workflow for News Citation Preference Analysis
#
# This workflow analyzes how different patterns of news citations affect
# user preferences in AI search responses using a Bradley-Terry model approach.

import os
from pathlib import Path

# Configuration
configfile: "config/config.yaml"

# Define paths from config
INPUT_DIR = Path(config["cleaned_data_dir"])
OUTPUT_DIR = Path(config["analysis_dir"])
SCRIPTS_DIR = Path(workflow.basedir) / "scripts"

# Ensure output directory exists
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# Final outputs - includes all analysis components
rule all:
    input:
        OUTPUT_DIR / "preference_analysis_report.html",
        OUTPUT_DIR / "visualizations" / "individual_effects.png",
        OUTPUT_DIR / "visualizations" / "citation_style_effects.png",
        OUTPUT_DIR / "visualizations" / "model_comparison.png",
        OUTPUT_DIR / "bt_ratings_results.json",
        OUTPUT_DIR / "individual_effects_results.json",
        OUTPUT_DIR / "citation_style_effects_results.json"

# Phase 1: Data Preparation
rule prepare_data:
    input:
        citations = INPUT_DIR / "citations_enriched.parquet",
        responses = INPUT_DIR / "responses.parquet",
        threads = INPUT_DIR / "threads.parquet"
    output:
        threads = OUTPUT_DIR / "news_competitions.parquet",
        responses = OUTPUT_DIR / "news_competitions_responses.parquet",
        citations = OUTPUT_DIR / "news_competitions_citations.parquet"
    script:
        "scripts/prepare_news_competitions.py"

# Phase 2: Response Signal Computation
rule compute_response_signals:
    input:
        threads = OUTPUT_DIR / "news_competitions.parquet",
        responses = OUTPUT_DIR / "news_competitions_responses.parquet",
        citations = OUTPUT_DIR / "news_competitions_citations.parquet"
    output:
        OUTPUT_DIR / "news_competitions_response_signals.parquet"
    script:
        "scripts/compute_response_signals.py"

# Phase 3: Battle Data Creation
rule create_battles:
    input:
        threads = OUTPUT_DIR / "news_competitions.parquet",
        signals = OUTPUT_DIR / "news_competitions_response_signals.parquet"
    output:
        OUTPUT_DIR / "battle_data.parquet"
    script:
        "scripts/create_battle_data.py"

# Phase 4a: Bradley-Terry Ratings
rule compute_bt_ratings:
    input:
        OUTPUT_DIR / "battle_data.parquet"
    output:
        results = OUTPUT_DIR / "bt_ratings_results.json",
        coefficients = OUTPUT_DIR / "bt_ratings_coefficients.csv"
    script:
        "scripts/bt_ratings.py"

# Phase 4b: Individual Feature Effects
rule analyze_individual_effects:
    input:
        OUTPUT_DIR / "battle_data.parquet"
    output:
        results = OUTPUT_DIR / "individual_effects_results.json",
        coefficients = OUTPUT_DIR / "individual_effects_coefficients.csv"
    params:
        bootstrap_samples = config["statistical_analysis"]["bootstrap_samples"] // 2,  # Fewer samples for individual analysis
        random_seed = config["statistical_analysis"]["random_seed"]
    script:
        "scripts/individual_effects.py"

# Phase 4c: Citation Style Effects with Flexible Models
rule analyze_citation_style_effects:
    input:
        OUTPUT_DIR / "battle_data.parquet"
    output:
        results = OUTPUT_DIR / "citation_style_effects_results.json",
        coefficients = OUTPUT_DIR / "citation_style_effects_coefficients.csv"
    params:
        bootstrap_samples = config["statistical_analysis"]["bootstrap_samples"],
        random_seed = config["statistical_analysis"]["random_seed"]
    script:
        "scripts/citation_style_effects.py"


# Phase 5: Reporting and Visualization
rule generate_report:
    input:
        # All analysis results
        bt_ratings_results = OUTPUT_DIR / "bt_ratings_results.json",
        individual_effects_results = OUTPUT_DIR / "individual_effects_results.json",
        citation_style_effects_results = OUTPUT_DIR / "citation_style_effects_results.json",
        # All coefficients
        bt_ratings_coefficients = OUTPUT_DIR / "bt_ratings_coefficients.csv",
        individual_effects_coefficients = OUTPUT_DIR / "individual_effects_coefficients.csv",
        citation_style_effects_coefficients = OUTPUT_DIR / "citation_style_effects_coefficients.csv",
        # Battle data for context
        battle_data = OUTPUT_DIR / "battle_data.parquet"
    output:
        report = OUTPUT_DIR / "preference_analysis_report.html",
        individual_effects = OUTPUT_DIR / "visualizations" / "individual_effects.png",
        citation_style_effects = OUTPUT_DIR / "visualizations" / "citation_style_effects.png",
        model_comparison = OUTPUT_DIR / "visualizations" / "model_comparison.png"
    script:
        "scripts/generate_report.py"